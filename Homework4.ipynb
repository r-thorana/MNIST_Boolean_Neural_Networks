{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRVUziqz7hB"
      },
      "source": [
        "# Assignment 4\n",
        "\n",
        "This is an basecode for assignment 4 of Artificial Intelligence class (CSCE-4613), Fall 2021\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih72pU-4h0BT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NBXrZkzlhS"
      },
      "source": [
        "## Binary Network\n",
        "\n",
        "## Define a binary network class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkjOLlQh4B0"
      },
      "source": [
        "class BinaryNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [4]):\n",
        "    super(BinaryNetwork, self).__init__()\n",
        "    self.network_dims = [2] + hidden_dims + [1]\n",
        "    self.layers = [] \n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      activation = nn.Sigmoid()\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_O-MPTzxo1"
      },
      "source": [
        "### Define data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU9RPLbqi-tL"
      },
      "source": [
        "def generate_data(operator = \"AND\"):\n",
        "  assert operator in [\"AND\", \"OR\", \"XOR\", \"NOR\"], \"%s operator is not valid\" % operator\n",
        "  data = []\n",
        "  label = [] \n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      data.append([i, j])\n",
        "      if operator == \"AND\":\n",
        "        label.append(i & j)\n",
        "      elif operator == \"OR\":\n",
        "        label.append(i | j)\n",
        "      elif operator == \"XOR\":\n",
        "        label.append(i ^ j)\n",
        "      else:\n",
        "        label.append(not (i | j))\n",
        "  data = torch.as_tensor(data, dtype = torch.float32)\n",
        "  label = torch.as_tensor(label, dtype = torch.float32)\n",
        "  return data, label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rKa_T9az3G6"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbF7qM7LkqFc"
      },
      "source": [
        "model = BinaryNetwork( hidden_dims= [])\n",
        "model.train()\n",
        "print(model)\n",
        "operator = \"AND\" \n",
        "inputs, labels = generate_data(operator = operator)\n",
        "n_iters = 10\n",
        "learning_rate = 0.1\n",
        "bce_loss_fn = nn.BCELoss()\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "threshold = 0.5\n",
        "for i in range(1, n_iters + 1):\n",
        "  outputs = model(inputs)\n",
        "  outputs = outputs.reshape(-1)\n",
        "  \n",
        "  loss = bce_loss_fn(outputs, labels)\n",
        "  predictions = (outputs > threshold).long()\n",
        "  \n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  loss = loss.item() # Convert to Python Scalar\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  if i % 5 == 0:\n",
        "    print(\"[%d/%d]. Loss: %0.4f. Accuracy: %0.2f\" % (i, n_iters, loss, accuracy))\n",
        "\n",
        "model.eval()\n",
        "outputs = model(inputs)\n",
        "outputs = outputs.reshape(-1)\n",
        "predictions = (outputs > threshold).long()  \n",
        "accuracy = (predictions == labels).float().mean() * 100.\n",
        "accuracy = accuracy.item()\n",
        "print(\"Final Accuracy: %0.2f\" % (accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"%s_Network.pth\" % operator)\n",
        "  # model.load_state_dict(torch.load(\"%s_Network.pth\" % operator)) # Load model in the next time you use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5YlJ_I3NYg"
      },
      "source": [
        "## Digit Classification\n",
        "\n",
        "### Define Digit Classification Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI2eUjVG0Ssz"
      },
      "source": [
        "class DigitNetwork(nn.Module):\n",
        "  def __init__(self, hidden_dims = [128]):\n",
        "    super(DigitNetwork, self).__init__()\n",
        "    self.network_dims = [28 * 28] + hidden_dims + [10]\n",
        "    self.layers = [] \n",
        "    for i, dim in enumerate(self.network_dims[1:]):\n",
        "      prev_dim = self.network_dims[i]\n",
        "      dense = nn.Linear(in_features = prev_dim, out_features = dim, bias = True)\n",
        "      if i < len(self.network_dims[1:]) - 1:\n",
        "        activation = nn.Sigmoid() # Hidden Layer \n",
        "      else:\n",
        "        activation = nn.Softmax(dim=1) # Last Layer\n",
        "      self.layers += [dense, activation]\n",
        "    self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = layer(x)\n",
        "    if self.training == False:\n",
        "      x = self.layers[-1](x) \n",
        "    return x"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTjiev9CK4K"
      },
      "source": [
        "### Define Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUnVAlP85SGs"
      },
      "source": [
        "def create_data_generator(batch_size = 32, root = \"data\"):\n",
        "  train_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = True,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  test_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = False,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = False)\n",
        "  return train_loader, test_loader"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZSB2N3CTFd"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDmnwaOT66-S"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 1\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train() \n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "      \n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels) \n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step() \n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"MNIST_Network.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nZTwv1CbGl"
      },
      "source": [
        "### Define the evaluation framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLbEk4QZ6_4K"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 1\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork()\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(\"MNIST_Network.pth\"))\n",
        "\n",
        "total_accuracy = 0.0 \n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    \n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmpi69Q-bzDj"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "### ReLU Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWoO_sciAqDa"
      },
      "source": [
        "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-defining-new-autograd-functions\n",
        "class MyReLU(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJY_Gnvb7wP"
      },
      "source": [
        "#### Sigmoid Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj3ac-EVRvMz"
      },
      "source": [
        "class MySigmoid(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        ctx.save_for_backward(input)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of sigmoid function\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgjRo-W1b_CD"
      },
      "source": [
        "#### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyxyWGNaXvG_"
      },
      "source": [
        "class MyLinearFunction(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weights, bias):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        # weights is a C x D tensor, C and D are the dimension out input and ouput\n",
        "        # bias is D tensor\n",
        "        ctx.save_for_backward(input, weights, bias)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of linear function\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weights, bias = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input, grad_weights, and grad_bias\n",
        "\n",
        "class MyLinearLayer(nn.Module):\n",
        "  # You don't modify this layer\n",
        "  def __init__(self, in_features = 2, out_features = 4):\n",
        "    super(MyLinearLayer, self).__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
        "    self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "    self.linear_fn = MyLinearFunction.apply\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.linear_fn(input, self.weights, self.bias)\n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjXs20ecGBG"
      },
      "source": [
        "#### Testing Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fQHamjZMX1"
      },
      "source": [
        "class MyLinearNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyLinearNetwork, self).__init__()\n",
        "    self.linear_1 = MyLinearLayer(28 * 28, 128)\n",
        "    self.sigmoid_fn = MySigmoid.apply\n",
        "    self.linear_2 = MyLinearLayer(128, 10)\n",
        "    self.softmax_fn = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    x = self.linear_1(x)\n",
        "    x = self.sigmoid_fn(x)\n",
        "    x = self.linear_2(x)\n",
        "    if self.training == False:\n",
        "      x = self.softmax_fn(x)\n",
        "    return x "
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-PND4sBcwgM"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = MyLinearNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 1\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train() \n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    if cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "      \n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_fn(outputs, labels) \n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step() \n",
        "\n",
        "    predictions = torch.argmax(outputs, 1)\n",
        "    accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "    loss = loss.item() # Convert to Python Scalar\n",
        "    accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "total_accuracy = 0.0 \n",
        "model.eval()\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  if cuda:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    \n",
        "  outputs = model(images)\n",
        "\n",
        "  predictions = torch.argmax(outputs, 1)\n",
        "  accuracy = (predictions == labels).float().mean() * 100.\n",
        "\n",
        "  accuracy = accuracy.item() # Convert to Python Scalar\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP5Vc_zriFmK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}